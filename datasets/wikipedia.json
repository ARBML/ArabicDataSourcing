{
    "Name": "Wikipedia",
    "Subsets": [],
    "HF Link": "https://hf.co/datasets/legacy-datasets/wikipedia",
    "Link": "https://dumps.wikimedia.org/",
    "License": "CC BY-SA 3.0",
    "Year": 2022,
    "Language": "multilingual",
    "Dialect": "Modern Standard Arabic",
    "Domain": "wikipedia",
    "Form": "text",
    "Collection Style": "crawling",
    "Description": "Wikipedia dataset containing cleaned articles of all languages. The datasets are built from the Wikipedia dump (https://dumps.wikimedia.org/) with one split per language.",
    "Volume": "1,151,628",
    "Unit": "documents",
    "Ethical Risks": "Low",
    "Provider": "Wikimedia",
    "Derived From": "",
    "Paper Title": "",
    "Paper Link": "",
    "Script": "Arab",
    "Tokenized": "No",
    "Host": "other",
    "Access": "Free",
    "Cost": "",
    "Test Split": "No",
    "Tasks": "text generation, language modeling",
    "Venue Title": "",
    "Citations": "",
    "Venue Type": "",
    "Venue Name": "",
    "Authors": "",
    "Affiliations": "",
    "Abstract": "",
    "Added By": "Zaid Alyafeai"
}